{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\Артем\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 0.2382 - acc: 0.9267 - val_loss: 0.1069 - val_acc: 0.9657\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 261us/sample - loss: 0.1147 - acc: 0.9652 - val_loss: 0.0755 - val_acc: 0.9768\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 15s 254us/sample - loss: 0.0844 - acc: 0.9742 - val_loss: 0.0681 - val_acc: 0.9783\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 15s 249us/sample - loss: 0.0695 - acc: 0.9785 - val_loss: 0.0864 - val_acc: 0.9748\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 16s 264us/sample - loss: 0.0639 - acc: 0.9807 - val_loss: 0.0783 - val_acc: 0.9783\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 254us/sample - loss: 0.0524 - acc: 0.9838 - val_loss: 0.0690 - val_acc: 0.9806\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 0.0486 - acc: 0.9851 - val_loss: 0.0726 - val_acc: 0.9806\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 16s 265us/sample - loss: 0.0442 - acc: 0.9862 - val_loss: 0.0750 - val_acc: 0.9805\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.0402 - acc: 0.9875 - val_loss: 0.0853 - val_acc: 0.9777\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 15s 256us/sample - loss: 0.0400 - acc: 0.9880 - val_loss: 0.0660 - val_acc: 0.9830\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 15s 254us/sample - loss: 0.0328 - acc: 0.9894 - val_loss: 0.0843 - val_acc: 0.9810\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 0.0336 - acc: 0.9899 - val_loss: 0.0826 - val_acc: 0.9820\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.0332 - acc: 0.9902 - val_loss: 0.0769 - val_acc: 0.9827\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 15s 250us/sample - loss: 0.0321 - acc: 0.9906 - val_loss: 0.0914 - val_acc: 0.9784\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 0.0340 - acc: 0.9905 - val_loss: 0.0790 - val_acc: 0.9810\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 0.0281 - acc: 0.9919 - val_loss: 0.0811 - val_acc: 0.9831\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 15s 251us/sample - loss: 0.0282 - acc: 0.9913 - val_loss: 0.0684 - val_acc: 0.9846\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 15s 257us/sample - loss: 0.0234 - acc: 0.9932 - val_loss: 0.0859 - val_acc: 0.9826\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 15s 253us/sample - loss: 0.0285 - acc: 0.9920 - val_loss: 0.0829 - val_acc: 0.9843\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 15s 253us/sample - loss: 0.0252 - acc: 0.9926 - val_loss: 0.0893 - val_acc: 0.9819\n",
      "Test loss: 0.08928621453285039\n",
      "Test accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1514729e-20 3.1548277e-14 3.3627053e-11 ... 1.0000000e+00\n",
      "  1.7242171e-15 3.6448200e-10]\n",
      " [9.0328639e-17 7.4847810e-13 1.0000000e+00 ... 7.2948968e-15\n",
      "  9.0163142e-15 8.9232561e-20]\n",
      " [2.3126725e-26 1.0000000e+00 1.4996618e-14 ... 5.6602287e-13\n",
      "  2.1484665e-13 2.6350042e-20]\n",
      " ...\n",
      " [8.9987282e-21 3.8312666e-14 3.3825271e-17 ... 3.6696980e-16\n",
      "  2.2442011e-15 2.2330603e-12]\n",
      " [3.2385227e-23 5.6950843e-33 6.1163683e-26 ... 3.9004189e-30\n",
      "  3.4732156e-19 1.0716406e-23]\n",
      " [6.4035331e-22 1.8903563e-21 3.7319396e-24 ... 3.6795365e-32\n",
      "  8.5179248e-17 2.8663560e-26]]\n",
      "[7 2 1 ... 4 5 6]\n",
      "[[ 969    1    1    0    0    0    4    2    2    1]\n",
      " [   0 1125    4    0    0    1    2    1    2    0]\n",
      " [   1    1 1010    3    3    0    3    6    5    0]\n",
      " [   0    0    6  990    0    2    0    4    5    3]\n",
      " [   0    1    1    0  953    0    7    5    0   15]\n",
      " [   1    0    0    9    1  869    4    2    5    1]\n",
      " [   2    2    0    0    3    4  946    0    1    0]\n",
      " [   2    2    9    1    0    0    0 1009    3    2]\n",
      " [   1    0    1    2    2    2    1    4  958    3]\n",
      " [   0    2    0    2    6    1    2    3    3  990]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "Y_pred = model.predict(x_test)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "target_names = ['0', '1', '2','3','4','5','6','7','8','9']\n",
    "#print(classification_report(np.argmax(x_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Артем\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Артем\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "[[3.8115390e-20 4.0378342e-18 4.5256481e-17 ... 1.0000000e+00\n",
      "  1.1532992e-17 3.8470655e-12]\n",
      " [5.4871588e-17 2.1374796e-13 1.0000000e+00 ... 2.6993457e-19\n",
      "  2.5161725e-19 7.6497311e-25]\n",
      " [1.7102484e-18 1.0000000e+00 9.2796983e-15 ... 4.4534946e-14\n",
      "  3.2039330e-15 2.3283654e-20]\n",
      " ...\n",
      " [3.3660674e-30 3.9380516e-29 3.1682089e-25 ... 1.4112725e-19\n",
      "  1.2545911e-24 2.7601063e-17]\n",
      " [2.2233741e-16 1.7616508e-27 3.4980437e-32 ... 3.5940560e-23\n",
      "  6.5296623e-13 2.0454734e-23]\n",
      " [5.2430390e-17 1.9260818e-21 3.7774865e-24 ... 1.7933171e-25\n",
      "  1.1984914e-17 2.1185154e-18]]\n",
      "[7 2 1 ... 4 5 6]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       980\n",
      "          1       0.99      1.00      0.99      1135\n",
      "          2       0.99      0.98      0.98      1032\n",
      "          3       0.97      0.99      0.98      1010\n",
      "          4       0.99      0.99      0.99       982\n",
      "          5       0.99      0.97      0.98       892\n",
      "          6       0.99      0.98      0.99       958\n",
      "          7       0.99      0.98      0.98      1028\n",
      "          8       0.99      0.98      0.98       974\n",
      "          9       0.98      0.98      0.98      1009\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n",
      "[[ 975    1    0    1    0    0    1    0    1    1]\n",
      " [   0 1134    0    0    0    0    0    0    1    0]\n",
      " [   2    1 1014    7    1    0    0    5    2    0]\n",
      " [   0    0    1  997    0    1    0    5    3    3]\n",
      " [   0    0    3    0  969    0    3    0    0    7]\n",
      " [   1    0    0   13    1  868    3    1    3    2]\n",
      " [   4    3    0    1    5    5  939    0    1    0]\n",
      " [   2    4    5    2    0    0    0 1008    1    6]\n",
      " [   4    2    5    4    0    0    0    2  954    3]\n",
      " [   2    1    0    8    5    1    0    2    0  990]]\n"
     ]
    }
   ],
   "source": [
    "file_json = open(\"modelBEST_64.json\", \"r\")\n",
    "load_json = file_json.read()\n",
    "file_json.close()\n",
    "load = tensorflow.keras.models.model_from_json(load_json)\n",
    "load.load_weights(\"modelBEST_64.h5\")\n",
    "\n",
    "Y_pred = load.predict(x_test)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "target_names = ['0', '1', '2','3','4','5','6','7','8','9']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
